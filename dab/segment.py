# AUTOGENERATED! DO NOT EDIT! File to edit: food_segment.ipynb (unless otherwise specified).

__all__ = ['saved_models_dir', 'saved_model_url_root', 'saved_model_name', 'model', 'crop_image_to_square', 'inference',
           'exptrapolate', 'get_food_segment']

# Cell
import numpy as np
import os


import sys
sys.path.insert(0,'STEGO/src/')


from os.path import join
import wget
from train_segmentation import LitUnsupervisedSegmenter
from PIL import Image
import requests
from io import BytesIO
from torchvision.transforms.functional import to_tensor
from utils import get_transform
import matplotlib.pyplot as plt
from utils import unnorm, remove_axes
from PIL import Image, ImageOps
import torchvision.transforms as T

import torch.nn.functional as F
from crf import dense_crf
import torch

# Cell
saved_models_dir = join("..", "saved_models")
os.makedirs(saved_models_dir, exist_ok=True)

saved_model_url_root = "https://marhamilresearch4.blob.core.windows.net/stego-public/saved_models/"
saved_model_name = "cocostuff27_vit_base_5.ckpt"
if not os.path.exists(join(saved_models_dir, saved_model_name)):
  wget.download(saved_model_url_root + saved_model_name, join(saved_models_dir, saved_model_name))
model = LitUnsupervisedSegmenter.load_from_checkpoint(join(saved_models_dir, saved_model_name)).cuda()

# Cell
def crop_image_to_square(img):
    height = img.size[1]//2*2
    left  = int((img.size[0]-height)/2)
    right =      img.size[0]-left
    return img.crop((left,0,right,height))

# Cell
def inference(img):
    transform = get_transform(448, False, "center")
    img = transform(img).unsqueeze(0).cuda()

    with torch.no_grad():
        code1 = model(img)
        code2 = model(img.flip(dims=[3]))
        code  = (code1 + code2.flip(dims=[3])) / 2
        code = F.interpolate(code, img.shape[-2:], mode='bilinear', align_corners=False)
        linear_probs = torch.log_softmax(model.linear_probe(code), dim=1).cpu()

        single_img = img[0].cpu()
        return dense_crf(single_img, linear_probs[0]).argmax(0)

# Cell
def exptrapolate(t,size):
    t = torch.Tensor(t).unsqueeze(0)
    t = torch.nn.functional.upsample(t,               (size)).squeeze(0)
    return torch.nn.functional.upsample(t.T.unsqueeze(0),(size)).squeeze(0)

# Cell
def get_food_segment(img):

  img = crop_image_to_square(img)
  pred = inference(img)

  food_class = 2
  pred[pred!=food_class]=0
  pred[pred==food_class]=1
  mask = exptrapolate(pred,img.size[1])
  pred = inference(img)
  food_class = 2

  pred[pred!=food_class]=0
  pred[pred==food_class]=1
  mask = exptrapolate(pred,img.size[1])
  img = np.array(img) * np.stack([mask]*3).T
  return Image.fromarray(img.astype(np.uint8))