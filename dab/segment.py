# AUTOGENERATED! DO NOT EDIT! File to edit: food_segment.ipynb (unless otherwise specified).

__all__ = ['saved_models_dir', 'saved_model_url_root', 'saved_model_name', 'model', 'get_food_segment']

# Cell
import numpy as np
import os


import sys
sys.path.insert(0,'STEGO/src/')


from os.path import join
import wget
from train_segmentation import LitUnsupervisedSegmenter
from PIL import Image
import requests
from io import BytesIO
from torchvision.transforms.functional import to_tensor
from utils import get_transform
import matplotlib.pyplot as plt
from utils import unnorm, remove_axes
from PIL import Image, ImageOps
import torchvision.transforms as T

import torch.nn.functional as F
from crf import dense_crf
import torch

# Cell
saved_models_dir = join("..", "saved_models")
os.makedirs(saved_models_dir, exist_ok=True)

saved_model_url_root = "https://marhamilresearch4.blob.core.windows.net/stego-public/saved_models/"
saved_model_name = "cocostuff27_vit_base_5.ckpt"
if not os.path.exists(join(saved_models_dir, saved_model_name)):
  wget.download(saved_model_url_root + saved_model_name, join(saved_models_dir, saved_model_name))
model = LitUnsupervisedSegmenter.load_from_checkpoint(join(saved_models_dir, saved_model_name)).cuda()

# Cell
def get_food_segment(img):


  transform = get_transform(448, False, "center")
  img = transform(img).unsqueeze(0).cuda()

  with torch.no_grad():
    code1 = model(img)
    code2 = model(img.flip(dims=[3]))
    code  = (code1 + code2.flip(dims=[3])) / 2
    code = F.interpolate(code, img.shape[-2:], mode='bilinear', align_corners=False)
    linear_probs = torch.log_softmax(model.linear_probe(code), dim=1).cpu()

    single_img = img[0].cpu()
    linear_pred = dense_crf(single_img, linear_probs[0]).argmax(0)

  linear_pred[linear_pred!=2]=0
  linear_pred[linear_pred==2]=1
  img = unnorm(img)[0].permute(1,2,0).cpu()

  res = img * np.transpose(np.array([linear_pred.T,]*3))
  transform = T.ToPILImage()
  img = transform(res.T)
  img = img.rotate(-90)
  return ImageOps.mirror(img)